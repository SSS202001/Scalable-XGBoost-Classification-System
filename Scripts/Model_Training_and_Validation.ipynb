{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "109bALxh_xVI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\Siddhant\\AppData\\Local\\Temp\\ipykernel_39404\\4264343828.py:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  csv_file_path = \"E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\\processed_data.csv\"\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\\processed_data.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEnTwaBAWAZ"
   },
   "source": [
    "# 1. Modify the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gONUm12WAaot"
   },
   "source": [
    "We are going to transform the target 'Class' column to have values 0,1,2 instead of 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EOdpnjta__sK"
   },
   "outputs": [],
   "source": [
    "# 1. Make the target column values are encoded starting from 0\n",
    "df['Class'] = df['Class'] - df['Class'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G-_nFCZAlPq"
   },
   "source": [
    "# 2. Divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XlStzdVUAn_a"
   },
   "outputs": [],
   "source": [
    "# 2. Divide the dataset into X and y (y is 'Class' column), and stratify the data\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L-Xja-rAr81"
   },
   "source": [
    "# 3. Split the dataset & Calculate the class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the test dataset remains unseen by the model, the same random state used in the hyperparameter tuning process is applied when splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JPMgZsZuAp_y"
   },
   "outputs": [],
   "source": [
    "# 3. Split it into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Pass class weights as sample weights\n",
    "sample_weights = np.vectorize(class_weight_dict.get)(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_ErFqQZAxXy"
   },
   "source": [
    "# 4. Define the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gBxba60rAwo6"
   },
   "outputs": [],
   "source": [
    "# 4. Define the XGBoost model\n",
    "model = XGBClassifier(eval_metric='aucpr', subsample = 0.9, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DPm5iz5jXwB"
   },
   "source": [
    "# 5. Model Training with Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hyperparameters were obtained as the result of the hyperparameter tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vBe-JpV8A_eL"
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.2,\n",
    "    'gamma': 0.15,\n",
    "    'reg_lambda': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KBCDdIOmj312"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Prepare the data in DMatrix format (needed for xgboost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)\n",
    "\n",
    "# Set the parameters for training\n",
    "param = {\n",
    "    'objective': 'multi:softprob', \n",
    "    'num_class': len(np.unique(y_train)),  # Number of classes\n",
    "    'eval_metric': 'aucpr',  # Use AUC PR (Area Under Precision-Recall Curve)\n",
    "    **best_params  # Add any additional parameters found in your grid search or previous tuning\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cross-validation was used here to evaluate the model's performance across multiple subsets of the data, ensuring a more reliable estimate of its generalization ability by reducing variance and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdpTqzblj4Yw",
    "outputId": "52f4d882-b328-4a6f-e79a-4229f6a1b4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.80019+0.00015\ttest-aucpr:0.79859+0.00050\n",
      "[1]\ttrain-aucpr:0.80140+0.00031\ttest-aucpr:0.79949+0.00048\n",
      "[2]\ttrain-aucpr:0.80214+0.00060\ttest-aucpr:0.79987+0.00042\n",
      "[3]\ttrain-aucpr:0.80258+0.00071\ttest-aucpr:0.80009+0.00062\n",
      "[4]\ttrain-aucpr:0.80285+0.00076\ttest-aucpr:0.80013+0.00069\n",
      "[5]\ttrain-aucpr:0.80302+0.00069\ttest-aucpr:0.80011+0.00068\n",
      "[6]\ttrain-aucpr:0.80324+0.00071\ttest-aucpr:0.80010+0.00066\n",
      "[7]\ttrain-aucpr:0.80362+0.00059\ttest-aucpr:0.80043+0.00088\n",
      "[8]\ttrain-aucpr:0.80400+0.00034\ttest-aucpr:0.80072+0.00083\n",
      "[9]\ttrain-aucpr:0.80420+0.00032\ttest-aucpr:0.80074+0.00086\n",
      "[10]\ttrain-aucpr:0.80436+0.00023\ttest-aucpr:0.80075+0.00089\n",
      "[11]\ttrain-aucpr:0.80452+0.00021\ttest-aucpr:0.80072+0.00087\n",
      "[12]\ttrain-aucpr:0.80473+0.00029\ttest-aucpr:0.80077+0.00086\n",
      "[13]\ttrain-aucpr:0.80498+0.00017\ttest-aucpr:0.80073+0.00087\n",
      "[14]\ttrain-aucpr:0.80550+0.00032\ttest-aucpr:0.80075+0.00095\n",
      "[15]\ttrain-aucpr:0.80608+0.00030\ttest-aucpr:0.80084+0.00104\n",
      "[16]\ttrain-aucpr:0.80652+0.00027\ttest-aucpr:0.80100+0.00102\n",
      "[17]\ttrain-aucpr:0.80683+0.00047\ttest-aucpr:0.80085+0.00111\n",
      "[18]\ttrain-aucpr:0.80721+0.00049\ttest-aucpr:0.80083+0.00122\n",
      "[19]\ttrain-aucpr:0.80787+0.00041\ttest-aucpr:0.80072+0.00124\n",
      "[20]\ttrain-aucpr:0.80816+0.00052\ttest-aucpr:0.80069+0.00122\n",
      "[21]\ttrain-aucpr:0.80863+0.00060\ttest-aucpr:0.80069+0.00111\n",
      "[22]\ttrain-aucpr:0.80906+0.00068\ttest-aucpr:0.80063+0.00122\n",
      "[23]\ttrain-aucpr:0.80968+0.00047\ttest-aucpr:0.80061+0.00116\n",
      "[24]\ttrain-aucpr:0.81036+0.00027\ttest-aucpr:0.80060+0.00116\n",
      "[25]\ttrain-aucpr:0.81064+0.00032\ttest-aucpr:0.80057+0.00116\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation with StratifiedKFold\n",
    "cv_results = xgb.cv(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,  # Set a large number of rounds to allow early stopping\n",
    "    nfold=5,  # Use 5-fold cross-validation\n",
    "    early_stopping_rounds=10,  # Stop after 10 rounds of no improvement\n",
    "    verbose_eval=True,  # Show evaluation metrics\n",
    "    stratified=True,  # Ensure stratification for each fold\n",
    "    metrics={'aucpr'}  # Use AUC PR as the evaluation metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZeotym5lB8F",
    "outputId": "fea2f81f-a680-4bbd-8945-f52bc2de63d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "    train-aucpr-mean  train-aucpr-std  test-aucpr-mean  test-aucpr-std\n",
      "0           0.800187         0.000148         0.798588        0.000497\n",
      "1           0.801403         0.000308         0.799494        0.000475\n",
      "2           0.802142         0.000596         0.799870        0.000420\n",
      "3           0.802579         0.000714         0.800089        0.000621\n",
      "4           0.802848         0.000757         0.800134        0.000691\n",
      "5           0.803020         0.000694         0.800113        0.000676\n",
      "6           0.803241         0.000708         0.800096        0.000665\n",
      "7           0.803622         0.000593         0.800429        0.000877\n",
      "8           0.804002         0.000340         0.800722        0.000829\n",
      "9           0.804204         0.000316         0.800744        0.000856\n",
      "10          0.804356         0.000231         0.800752        0.000894\n",
      "11          0.804516         0.000209         0.800718        0.000873\n",
      "12          0.804735         0.000290         0.800772        0.000860\n",
      "13          0.804985         0.000167         0.800732        0.000866\n",
      "14          0.805505         0.000322         0.800746        0.000948\n",
      "15          0.806083         0.000298         0.800841        0.001044\n",
      "16          0.806518         0.000272         0.800996        0.001021\n",
      "Best Early Stopping Round (based on AUC PR): 16\n",
      "Best ROC AUC OVR at Best Iteration: 0.8009960147857335\n"
     ]
    }
   ],
   "source": [
    "# Print the cross-validation results\n",
    "print(\"Cross-validation results:\")\n",
    "print(cv_results)\n",
    "\n",
    "# Get the best iteration (best boosting round) based on the ROC AUC OVR (AUC PR)\n",
    "best_iteration = cv_results['test-aucpr-mean'].idxmax()\n",
    "print(f\"Best Early Stopping Round (based on AUC PR): {best_iteration}\")\n",
    "\n",
    "# The ROC AUC OVR score corresponding to this best iteration\n",
    "best_roc_auc_ovr = cv_results.loc[best_iteration, 'test-aucpr-mean']\n",
    "print(f\"Best ROC AUC OVR at Best Iteration: {best_roc_auc_ovr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR9soxrqlONQ"
   },
   "source": [
    "# 6. Train the Full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the full training dataset with the early stopping round value obtained from previous step, also utilizing feature mapping, to enable model saving with the ONNX library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed X_train columns: Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6'], dtype='object')\n",
      "Renamed X_test columns: Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the custom feature mapping\n",
    "feature_mapping = {\"B\": \"f0\", \"D\": \"f1\", \"F\": \"f2\", \"I\": \"f3\", \"J\": \"f4\", \"L\": \"f5\", \"M\": \"f6\"}\n",
    "\n",
    "# Rename columns using the mapping\n",
    "X_train_renamed = X_train.rename(columns=feature_mapping)\n",
    "X_test_renamed = X_test.rename(columns=feature_mapping)\n",
    "\n",
    "# Print the renamed column names for verification\n",
    "print(\"Renamed X_train columns:\", X_train_renamed.columns)\n",
    "print(\"Renamed X_test columns:\", X_test_renamed.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQD--2gtlCtm",
    "outputId": "b3eed9d9-7830-4656-8935-3917c15c6ea6"
   },
   "outputs": [],
   "source": [
    "# Prepare the data in DMatrix format (needed for xgboost)\n",
    "dtrain = xgb.DMatrix(X_train_renamed, label=y_train, weight=sample_weights)\n",
    "\n",
    "best_num_boost_round = cv_results.shape[0]\n",
    "\n",
    "model = xgb.train(\n",
    "    params=param,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=best_num_boost_round\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ_g9YHjliXf"
   },
   "source": [
    "# 7: Evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "-J4QRINcljLP"
   },
   "outputs": [],
   "source": [
    "# Step 7: Evaluate model performance on the test set\n",
    "\n",
    "# First, prepare the test set with sample weights\n",
    "sample_weights_test = np.vectorize(class_weight_dict.get)(y_test)\n",
    "\n",
    "# Prepare the test data in DMatrix format\n",
    "dtest = xgb.DMatrix(X_test_renamed, weight=sample_weights_test)\n",
    "\n",
    "# Predict probabilities on the test set using the best iteration (use softprob for probabilities)\n",
    "y_pred_prob = model.predict(dtest, iteration_range=(0, best_iteration), output_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ewx5PA_PllLQ",
    "outputId": "2cc303e3-ebcd-45bb-80db-732178e27c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score on Test Data: 0.8920\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro')\n",
    "print(f\"AUC Score on Test Data: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noPVWft1ltBS",
    "outputId": "33615880-9d58-4002-c513-c1bc2fc76352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72     36119\n",
      "           1       0.75      1.00      0.86     89977\n",
      "           2       0.84      0.74      0.79    113904\n",
      "\n",
      "    accuracy                           0.81    240000\n",
      "   macro avg       0.87      0.77      0.79    240000\n",
      "weighted avg       0.83      0.81      0.80    240000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for detailed metrics (convert probabilities to class labels)\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_classes = y_pred_prob.argmax(axis=1)  # Convert probabilities to class labels\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))  # Display detailed classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Comparing model performance with Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Naive Bayes model is trained on the original dataset, and performance metrics comparable to those of the XGBoost model are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\Siddhant\\AppData\\Local\\Temp\\ipykernel_32316\\4282826796.py:3: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  data = pd.read_csv(\"E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\\data_public.csv\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv(\"E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\\data_public.csv\")\n",
    "\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('Class', axis=1)  # Features\n",
    "y = data['Class']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set (needed for AUCPR)\n",
    "y_pred_prob = model.predict_proba(X_test)  # predict_proba gives probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCPR: 0.6396\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.56      0.53     36189\n",
      "           2       0.75      1.00      0.86     89845\n",
      "           3       0.80      0.56      0.66    113966\n",
      "\n",
      "    accuracy                           0.72    240000\n",
      "   macro avg       0.68      0.71      0.68    240000\n",
      "weighted avg       0.74      0.72      0.71    240000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Calculate AUCPR (Area Under the Precision-Recall Curve) \n",
    "y_test_binary = label_binarize(y_test, classes=np.unique(y))  \n",
    "\n",
    "# Compute AUCPR for the positive class \n",
    "aupr = average_precision_score(y_test_binary, y_pred_prob, average='macro')\n",
    "print(f\"AUCPR: {aupr:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred_classes = model.predict(X_test)  \n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ksm2lYRmX1j"
   },
   "source": [
    "# 9: Download and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "eSwFEbATsBPQ"
   },
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "xNIKxdACu4Li"
   },
   "outputs": [],
   "source": [
    "# Define the input type for ONNX\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train_renamed.shape[1]]))]\n",
    "\n",
    "# Convert the model to ONNX\n",
    "onnx_model = onnxmltools.convert_xgboost(model, initial_types=initial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\\xgboost_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory and model name\n",
    "model_dir = r\"E:\\IIT Chicago\\Sem 3\\Data Preparation and Analysis - CSP 571\\Project\\Final Submission\"   # Replace with your desired directory path\n",
    "model_name = \"xgboost_model.onnx\"  # You can change the model name if needed\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Combine directory and model name into a full path\n",
    "onnx_file_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(onnx_file_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"Model saved to {onnx_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DPA_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
